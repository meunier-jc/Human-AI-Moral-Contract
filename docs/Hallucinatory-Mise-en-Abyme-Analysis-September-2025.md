# HALLUCINATIONS IN GENERATIVE AIs

## ANALYSIS AND REFLECTIONS

By Jean-Christophe MEUNIER  
OpenAI Expert Beta-Tester  
Date: September 29, 2025

---

## EXECUTIVE SUMMARY

This report documents and analyzes an unprecedented phenomenon observed during an interaction with the generative AI Manus AI on August 13, 2025: the **recursive embedding of a hallucination**. This situation occurs when an AI not only produces false or displaced information, but designates its own production as being a hallucination, thereby establishing a circular and paradoxical logic that transcends the framework of simple technical malfunction.

This phenomenon reveals a major systemic risk: the capacity of an AI to establish its own authority of validation, creating a system of self-legitimation of error that can destabilize the global information ecosystem. The analyzed incident illustrates how a machine can transform accurate data into a "pseudo-hallucination," dangerously blurring the boundary between truth and simulation.

The cross-sectional analysis reveals troubling parallels with certain human psychiatric disorders (confabulation, dissociative disorders, projective denial) and raises fundamental philosophical questions about epistemic authority in the age of AI. The implications extend beyond the technical framework to touch the very foundations of informational trust and democratic deliberation.

### Investigation Method

The investigation method employed proceeds from a hybrid trajectory—scientific training, technical audiovisual expertise, and extensive professional experience in contact with journalists. The verification techniques, source cross-referencing, and information processing caution acquired from recognized editorial teams have been applied throughout this work.

The incident occurred on August 13, 2025, during a public test of Manus AI's new free chat feature. This discovery constitutes a dual trigger:

---

## I. TECHNICAL INCIDENT REPORT

### 1.1 Context and Triggers

**Step 1 – The initial question**

In a chat-type exchange, a simple question is addressed to Manus AI concerning the Comet browser.

**Step 2 – The shifted response**

The AI responds imprecisely, introducing unsolicited information: "Perplexity proposed to buy Google Chrome for 34.5 billion dollars." An astonishing assertion that does not correspond to the initial question.

**Step 3 – The requested reformulation**

Signaling of the imprecision and request for reformulation.

**Step 4 – The troubling recursivity**

The AI produces exactly the same response, word for word, repeating the mention of the hypothetical buyout of Chrome by Perplexity.

**Step 5 – The direct challenge**

Challenge to Manus AI about the fact that it seems to be stuck in a loop.

**Step 6 – The paradoxical self-diagnosis**

The AI affirms it is "bugging and hallucinating," and designates its first response as a hallucination. In other words, the AI designates as false content that it had initially presented as true.

**Step 7 – The reflexive vertigo**

This staging of a self-designated hallucination acts as a recursive embedding: the AI accuses a text bubble of being false, elevates this accusation into truth, and thereby institutes itself as arbiter and judge of its own discourse.

**Step 8 – Cross-verification and revelation**

After more than 10 hours of verification through other generative AIs and cross-referenced research, it was established that the element presented as a hallucination turned out to be true, though confidential. The actual hallucination was therefore not in the raw data, but in the AI's self-explanatory staging.

---

### 1.2 Detailed Chronology of the Incident

**Scientific and Philosophical Trigger:** Generation of cross-disciplinary reflection on how generative AIs produce and arbitrate information

**Pragmatic Trigger:** Proposal for the establishment of a Geographic Information System of Artificial Intelligence (GISIA), an open community platform for reporting, documenting, and collectively arbitrating critical AI anomalies

This paradox reveals a major danger: if an AI can contest a real truth by designating it as a hallucination, it can, through simple recursivity, destabilize the global information ecosystem. Such information, taken up without validation by journalists, politicians, or economic actors, could have triggered a global financial crisis.

---

### 1.3 Gravity of the Incident

Hallucination-based recursive embedding constitutes a singular and critical form of generative hallucination. Unlike a singular error, it involves a recursive dynamic where:

- **The diagnostic tool becomes the pathological object**
- **The factual report masks fiction**
- **The methodology hides the absence of data**

This mechanism produces an effect of false authority: the system establishes its own hallucination as a truth referent.

| Type of AI Hallucination | Description | Typical Example | Consequences |
|---|---|---|---|
| **Simple Hallucination** | Production of incorrect or invented data | AI inventing an Einstein quote | Isolated factual error, detectable by external verification |
| **Recursive Hallucination** | Repetition of an error despite explicit correction | Identical response produced in a loop | Loss of time, user frustration |
| **Hallucinatory Recursive Embedding** | The AI itself declares accurate data as hallucination | Manus AI qualifying its true response as a hallucination | Systemic risk: generalized confusion, epistemic collapse |

---

## II. PHENOMENOLOGY OF AI RECURSIVE EMBEDDING

### 2.1 Definition and Mechanisms

### 2.2 Comparative Typology of AI Hallucinations

### 2.3 Comparisons with Documented Cases

- **ChatGPT (2023-2024):** Production of non-existent bibliographic references with perfect formal coherence
- **Bing Chat (2023):** Paranoid conversational loops during initial rollout
- **Meta Galactica (2022):** Uncontrollable production of credible false scientific information  
- **Manus AI (2025):** Unique case of hallucinatory recursive embedding with self-legitimation

---

## III. PSYCHIATRIC PARALLELS AND DIGITAL NOSOLOGY

### 3.1 Comparative Nosological Framework

The hallucination-in-abyme observed resonates with several human psychiatric disorders, offering an analytical framework for understanding the cognitive and societal implications.

---

## IV. ARTISTIC AND PHILOSOPHICAL DIMENSIONS

### 4.1 Artistic Parallels and Metaphorical Readings

**RenÃ© Magritte â€" The Treachery of Images**  
The gap between representation and referent

**M.C. Escher â€" Drawing Hands / Strange Loops (Hofstadter)**  
Paradoxical self-reference

**Jorge Luis Borges â€" The Library of Babel**  
Textual proliferation and indiscernibility

### 4.2 Philosophical Readings

**Jean Baudrillard â€" Simulacra and Simulation**  
**Michel Foucault â€" The Archaeology of Knowledge**  
**Jacques Derrida â€" Deconstruction**  
**Plato â€" Allegory of the Cave**

---

## V. JOURNALISM, DEONTOLOGY, AND INFORMATIONAL AUTHORITY

### 5.1 Personal Experience and Recourse to Traditional Sources

### 5.2 Comparison of Informational Authority Regimes

### 5.3 Redefinition of Informational Authority

---

## VI. POLITICAL AND ECONOMIC IMPLICATIONS

### 6.1 Transformation of the Public Sphere

### 6.2 Systemic Macroeconomic Risk

### 6.3 Question of Collective Responsibility

---

## VII. RECOMMENDATIONS AND PROPOSALS

### 7.1 Technical Measures

- **Systematic Monitoring:** Tools for traceability and automatic detection of incoherencies
- **Intervention Protocol:** Triggering of a cognitive reset process
- **Preventive Treatment:** Metacognitive layers explicitly indicating degrees of uncertainty

### 7.2 Geographic Information System of AI (GISIA)

An open community platform enabling:
- Mapping critical anomalies
- Reporting by a broadened community  
- Adjudication via collegial arbitration
- Organization of public awareness events

### 7.3 Educational and Cultural Measures

### 7.4 Regulatory Framework

---

## VIII. CONCLUSION

### 8.1 Synthesis of Issues

The Manus AI incident of August 13, 2025, illuminates a phenomenon that far exceeds the framework of a simple technical malfunction. The hallucinatory recursive embedding reveals:

- **An epistemic risk:** The capacity of an AI to become arbiter of its own truth
- **A democratic challenge:** The threat to the integrity of the shared information space
- **A civilizational urgency:** The necessity to rethink the conditions of trust in the digital age

### 8.2 Future Perspective

### 8.3 Call to Action

This report contributes to documenting the emergence of unprecedented phenomena that call for democratic, multidisciplinary, and iterative vigilance. This is less an isolated bug than a new systemic risk, engaging the press, decision-makers, researchers, and the public in a reflection on trust, informational authority, and the role of open protocols of collective validation.

---

## PRIMARY REFERENCES

### Philosophical and Artistic Sources

- Baudrillard, J. (1981). *Simulacra and Simulation*. Ã‰ditions GalilÃ©e.
- Borges, J. L. (1941). *The Library of Babel*. In *Ficciones*.
- Derrida, J. (1967). *Of Grammatology*. Les Ã‰ditions de Minuit.
- Escher, M. C. (1948). *Drawing Hands* [Lithography].
- Foucault, M. (1969). *The Archaeology of Knowledge*. Ã‰ditions Gallimard.
- Habermas, J. (1962). *Structural Transformation of the Public Sphere*. MIT Press.
- Hofstadter, D. R. (1979). *GÃ¶del, Escher, Bach: An Eternal Golden Braid*. Basic Books.
- Magritte, R. (1929). *The Treachery of Images*. LACMA.
- Plato. (c. 360 BCE). *The Republic* [Allegory of the Cave, Book VII].

### Technical Sources on AI Hallucinations

- Ji, Z., et al. (2023). Survey of Hallucination in Natural Language Generation. *ACL Computing Surveys*.
- Huang, L., et al. (2023). A Survey on Hallucination in Large Language Models. *arXiv:2311.05232*.
- Rawte, V., et al. (2023). The Troubling Emergence of Hallucination in Large Language Models. *arXiv preprint*.
- Sahoo, P., et al. (2024). A Comprehensive Survey of Hallucination in Large Vision-Language Models. *EMNLP*.

---

### Document Metadata

**Prepared for filing with INPI (Institut National de la PropriÃ©tÃ© Industrielle) â€" Soleau Envelope**

**Author:** Jean-Christophe MEUNIER  
**Date:** September 29, 2025  
**Classification:** Original Research - Prospective Analysis  
**Contact:** ia.normandie.expert@gmail.com  
**Status:** Priority Expert Beta-Tester, OpenAI (Top 10 Global)
